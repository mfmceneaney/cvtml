{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hipopy.hipopy as hp\n",
    "import numpy.ma as ma\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch_geometric as tg\n",
    "from torch_geometric.data import Data, InMemoryDataset, download_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set params for reading data\n",
    "files = \"/work/clas12/jnp/cvt/out_gen_cvt_rgbbg50na.hipo\"\n",
    "banks = [\n",
    "    \"BST::HitsPos\"\n",
    "]\n",
    "keys = [\n",
    "    'BST::HitsPos_ID',\n",
    "    'BST::HitsPos_sector',\n",
    "    'BST::HitsPos_layer',\n",
    "    'BST::HitsPos_strip',\n",
    "    'BST::HitsPos_r1',\n",
    "    'BST::HitsPos_theta1',\n",
    "    'BST::HitsPos_phi1',\n",
    "    'BST::HitsPos_r2',\n",
    "    'BST::HitsPos_theta2',\n",
    "    'BST::HitsPos_phi2',\n",
    "    'BST::HitsPos_tstatus',\n",
    "    'BST::HitsPos_rstatus'\n",
    "]\n",
    "step = 1\n",
    "max_events = 10**2\n",
    "label_keys = keys[10:]\n",
    "data_keys = keys[4:10]\n",
    "datalist = []\n",
    "\n",
    "# Loop HIPO files to create graphs\n",
    "for idx, batch in tqdm(enumerate(hp.iterate(files,banks=banks,step=step,experimental=True))): #NOTE: RETURNS ARRAYS WITH SHAPE (NEVENTS=1,NROWS)\n",
    "    \n",
    "    # Check labels tstatus and rstatus\n",
    "    rec_mask = torch.eq(batch[label_keys[1]][0],1) #NOTE: ONLY GET TRACKS THAT ARE RECONSTRUCTED\n",
    "    y = torch.tensor(ma.array(batch[label_keys[0]][0])[rec_mask], dtype=torch.long) #NOTE: IF YOU WANT TO DO NODE CLASSIFICATION\n",
    "    y = torch.tensor([1 if y.sum().item()==y.shape[0] else 0],dtype=torch.long) #NOTE: IF YOU JUST WANT ALL THE TRACKS TO BE TRUE\n",
    "\n",
    "    # Get data arrays\n",
    "    x = torch.moveaxis(torch.tensor([ma.array(batch[key][0])[rec_mask] for key in data_keys], dtype=torch.float),[0,1],[1,0])\n",
    "    nnodes = x.shape[0] #NOTE: AFTER TORCH.MOVEAXIS ABOVE x.shape should = (NNODES,NFEATURES)\n",
    "    if nnodes<=0: continue\n",
    "    \n",
    "    # Create graph\n",
    "    edge_index = torch.tensor([[i for i in range(nnodes)],[i+1 if i<nnodes-1 else 0 for i in range(nnodes)]],dtype=torch.long)\n",
    "    data = Data(x=x, edge_index=edge_index, y=y)\n",
    "    \n",
    "    # Sanity check\n",
    "    if torch.max(edge_index)>=nnodes or torch.min(edge_index)<0:\n",
    "        print(\"DEBUGGING: ERROR: torch.max(edge_index)>=nnodes\")\n",
    "        print(\"DEBUGGING: edge_index = \",edge_index)\n",
    "        print(\"DEBUGGING: nnodes = \",nnodes)\n",
    "        print(\"DEGBUGGING: idx = \",idx)\n",
    "    if edge_index.shape[1]!=nnodes:\n",
    "        print(\"DEBUGGING: ERROR: edge_index.shape[1]!=nnodes\")\n",
    "        print(\"DEBUGGING: edge_index = \",edge_index)\n",
    "        print(\"DEBUGGING: nnodes = \",nnodes)\n",
    "        print(\"DEGBUGGING: idx = \",idx)\n",
    "    \n",
    "    # Add graph to list\n",
    "    datalist.append(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset class\n",
    "class MyOwnDataset(InMemoryDataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None, pre_filter=None, data_list=None):\n",
    "        self.data_list = data_list\n",
    "        super().__init__(root, transform, pre_transform, pre_filter)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return ['some_file_1', 'some_file_2']\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['data.pt']\n",
    "\n",
    "    def process(self):\n",
    "        # Read data into huge `Data` list.\n",
    "        data_list = self.data_list\n",
    "\n",
    "        if self.pre_filter is not None:\n",
    "            data_list = [data for data in data_list if self.pre_filter(data)]\n",
    "\n",
    "        if self.pre_transform is not None:\n",
    "            data_list = [self.pre_transform(data) for data in data_list]\n",
    "\n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])\n",
    "\n",
    "# Create dataset\n",
    "root = \"pyg_datasets\" #NOTE: DATA WILL BE SAVED IN <root>/processed/data.pt\n",
    "mydataset = MyOwnDataset(root, transform=None, pre_transform=None, pre_filter=None, data_list=data_list)\n",
    "print(mydataset[0])\n",
    "print(len(mydataset))#NOTE: YOU SHOULD SEE the Processing...\\nDone! message from dataset.process() being called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!du -sh $root\n",
    "!ls -lrth $root/processed/data.pt"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
